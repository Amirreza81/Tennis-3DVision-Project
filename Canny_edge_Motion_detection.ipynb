{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42b62ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Input and output file paths\n",
    "input_video_path = '1.avi'\n",
    "output_video_path = '2.avi'\n",
    "\n",
    "# Open the video file\n",
    "video_capture = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# Get the video properties\n",
    "fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create a VideoWriter object for output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height), isColor=False)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Break the loop if the video has ended\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Use Canny edge detector\n",
    "    edges = cv2.Canny(blurred, 50, 150)  # Adjust the thresholds as needed\n",
    "\n",
    "    # Write the Canny edges to the output video\n",
    "    out.write(edges)\n",
    "\n",
    "    # Display the Canny edges (optional)\n",
    "    cv2.imshow('Canny Edges', edges)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture and VideoWriter objects\n",
    "video_capture.release()\n",
    "out.release()\n",
    "\n",
    "# Destroy all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57ea6be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fed726a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import cv2\\nimport numpy as np\\n\\n\\ndef apply_canny_and_remove_static(input_video_path, output_canny_video_path):\\n    # Open the video file\\n    video_capture = cv2.VideoCapture(input_video_path)\\n\\n    # Get the video properties\\n    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\\n    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\\n    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\\n\\n    # Define the codec for output video\\n    fourcc = cv2.VideoWriter_fourcc(*'XVID')\\n\\n    # Create VideoWriter object for output video\\n    out_canny = cv2.VideoWriter(output_canny_video_path, fourcc, fps, (width, height), isColor=False)\\n\\n    # Read the first frame to initialize\\n    ret, prev_frame = video_capture.read()\\n\\n    # Initialize a variable to keep track of cumulative motion\\n    cumulative_motion = np.zeros((height, width), dtype=np.uint8)\\n\\n    while True:\\n        # Read a frame from the video\\n        ret, frame = video_capture.read()\\n\\n        # Break the loop if the video has ended\\n        if not ret:\\n            break\\n\\n        # Convert frames to grayscale\\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\\n\\n        # Apply Canny edge detector\\n        edges_canny = cv2.Canny(gray, 50, 150)  # Adjust the thresholds as needed\\n\\n        # Write the Canny edges to the output video\\n        out_canny.write(edges_canny)\\n\\n        # Accumulate edges with motion\\n        cumulative_motion = cv2.bitwise_or(cumulative_motion, edges_canny)\\n\\n        # Remove stationary edges from current frame\\n        frame_no_static = cv2.subtract(gray, cumulative_motion)\\n\\n        # You can choose not to write the no_static video if you don't want it\\n\\n    # Release the VideoCapture and VideoWriter objects\\n    video_capture.release()\\n    out_canny.release()\\n\\n# Example usage\\ninput_video_path = '1.avi'\\noutput_canny_video_path = '11.avi'\\n\\napply_canny_and_remove_static(input_video_path, output_canny_video_path)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def apply_canny_and_remove_static(input_video_path, output_canny_video_path):\n",
    "    # Open the video file\n",
    "    video_capture = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "    # Get the video properties\n",
    "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the codec for output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "    # Create VideoWriter object for output video\n",
    "    out_canny = cv2.VideoWriter(output_canny_video_path, fourcc, fps, (width, height), isColor=False)\n",
    "\n",
    "    # Read the first frame to initialize\n",
    "    ret, prev_frame = video_capture.read()\n",
    "\n",
    "    # Initialize a variable to keep track of cumulative motion\n",
    "    cumulative_motion = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        # Break the loop if the video has ended\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert frames to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply Canny edge detector\n",
    "        edges_canny = cv2.Canny(gray, 50, 150)  # Adjust the thresholds as needed\n",
    "\n",
    "        # Write the Canny edges to the output video\n",
    "        out_canny.write(edges_canny)\n",
    "\n",
    "        # Accumulate edges with motion\n",
    "        cumulative_motion = cv2.bitwise_or(cumulative_motion, edges_canny)\n",
    "\n",
    "        # Remove stationary edges from current frame\n",
    "        frame_no_static = cv2.subtract(gray, cumulative_motion)\n",
    "\n",
    "        # You can choose not to write the no_static video if you don't want it\n",
    "\n",
    "    # Release the VideoCapture and VideoWriter objects\n",
    "    video_capture.release()\n",
    "    out_canny.release()\n",
    "\n",
    "# Example usage\n",
    "input_video_path = '1.avi'\n",
    "output_canny_video_path = '11.avi'\n",
    "\n",
    "apply_canny_and_remove_static(input_video_path, output_canny_video_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b135ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9639ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def apply_canny_and_remove_static(input_video_path, output_canny_video_path):\n",
    "    # Open the video file\n",
    "    video_capture = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "    # Get the video properties\n",
    "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the codec for output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "    # Create VideoWriter object for output video\n",
    "    out_canny = cv2.VideoWriter(output_canny_video_path, fourcc, fps, (width, height), isColor=False)\n",
    "\n",
    "    # Read the first frame to initialize\n",
    "    ret, prev_frame = video_capture.read()\n",
    "\n",
    "    # Initialize a variable to keep track of cumulative motion\n",
    "    cumulative_motion = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        # Break the loop if the video has ended\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert frames to grayscale\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate the absolute difference between consecutive frames\n",
    "        frame_diff = cv2.absdiff(prev_gray, gray)\n",
    "\n",
    "        # Apply Canny edge detector to the difference\n",
    "        edges_diff = cv2.Canny(frame_diff, 50, 150)  # Adjust the thresholds as needed\n",
    "\n",
    "        # Accumulate edges with motion\n",
    "        cumulative_motion = cv2.bitwise_or(cumulative_motion, edges_diff)\n",
    "\n",
    "        # Write the Canny edges to the output video\n",
    "        out_canny.write(edges_diff)\n",
    "\n",
    "        # Update the previous frame for the next iteration\n",
    "        prev_frame = frame.copy()\n",
    "\n",
    "    # Release the VideoCapture and VideoWriter objects\n",
    "    video_capture.release()\n",
    "    out_canny.release()\n",
    "\n",
    "# Example usage\n",
    "input_video_path = '1.avi'\n",
    "output_canny_video_path = '111.avi'\n",
    "\n",
    "apply_canny_and_remove_static(input_video_path, output_canny_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e2e6724",
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f594f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class EdgeDetector:\n",
    "    def __init__(self, min_distance=30, strength=50, temporal_window=10, temporal_weight=0.1):\n",
    "        self.min_distance = min_distance\n",
    "        self.strength = strength\n",
    "        self.temporal_window = temporal_window\n",
    "        self.temporal_weight = temporal_weight\n",
    "        self.prev_frames = []\n",
    "\n",
    "    def remove_noise_edges(self, edges):\n",
    "        cleaned_edges = np.zeros_like(edges)\n",
    "\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > self.min_distance:\n",
    "                cv2.drawContours(cleaned_edges, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "        return cleaned_edges\n",
    "\n",
    "    def enhance_edges(self, edges):\n",
    "        enhanced_edges = cv2.dilate(edges, None, iterations=self.strength)\n",
    "\n",
    "        return enhanced_edges\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        current_edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "        if self.prev_frames:\n",
    "            # Temporal smoothing by blending with nearby frames' edges\n",
    "            combined_edges = current_edges.copy()\n",
    "\n",
    "            for i in range(1, min(len(self.prev_frames), self.temporal_window)+1):\n",
    "                temporal_weight = self.temporal_weight / i  # Decrease weight for farther frames\n",
    "                combined_edges = cv2.addWeighted(combined_edges, 1 - temporal_weight, self.prev_frames[-i], temporal_weight, 0)\n",
    "\n",
    "            # Enhance the combined edges\n",
    "            enhanced_edges = self.enhance_edges(combined_edges)\n",
    "        else:\n",
    "            enhanced_edges = self.enhance_edges(current_edges)\n",
    "\n",
    "        # Update the temporal window\n",
    "        self.prev_frames.insert(0, current_edges)\n",
    "        if len(self.prev_frames) > self.temporal_window:\n",
    "            self.prev_frames.pop()\n",
    "\n",
    "        cleaned_edges = self.remove_noise_edges(enhanced_edges)\n",
    "\n",
    "        return cv2.bitwise_and(frame, frame, mask=cleaned_edges)\n",
    "\n",
    "def process_video(input_path, output_path):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "    edge_detector = EdgeDetector()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        result = edge_detector.process_frame(frame)\n",
    "        out.write(result)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "input_video_path = \"111.avi\"\n",
    "output_video_path = \"o.avi\"\n",
    "\n",
    "process_video(input_video_path, output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9be7bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e174f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"1.avi\")\n",
    "\n",
    "LEARNING_RATE = -1\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Obtain the width and height of the input video\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(\"out1.avi\", fourcc, cap.get(cv2.CAP_PROP_FPS), (width, height))\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply MOG\n",
    "    motion_mask = fgbg.apply(frame, LEARNING_RATE)\n",
    "\n",
    "    # Apply median filter to remove salt-and-pepper noise\n",
    "    motion_mask_smooth = cv2.medianBlur(motion_mask, 5)  # You can adjust the kernel size (5 in this case)\n",
    "\n",
    "    # Write smoothed motion mask to the output video\n",
    "    out.write(cv2.cvtColor(motion_mask_smooth, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e484999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f799ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def apply_canny_and_remove_static(input_video_path, output_canny_video_path):\n",
    "    # Open the video file\n",
    "    video_capture = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "    # Get the video properties\n",
    "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the codec for output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "    # Create VideoWriter object for output video\n",
    "    out_canny = cv2.VideoWriter(output_canny_video_path, fourcc, fps, (width, height), isColor=False)\n",
    "\n",
    "    # Read the first frame to initialize\n",
    "    ret, prev_frame = video_capture.read()\n",
    "\n",
    "    # Initialize a variable to keep track of cumulative motion\n",
    "    cumulative_motion = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        # Break the loop if the video has ended\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert frames to grayscale\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate the absolute difference between consecutive frames\n",
    "        frame_diff = cv2.absdiff(prev_gray, gray)\n",
    "\n",
    "        # Apply Canny edge detector to the difference\n",
    "        edges_diff = cv2.Canny(frame_diff, 50, 150)  # Adjust the thresholds as needed\n",
    "\n",
    "        # Accumulate edges with motion\n",
    "        cumulative_motion = cv2.bitwise_or(cumulative_motion, edges_diff)\n",
    "\n",
    "        # Write the Canny edges to the output video\n",
    "        out_canny.write(edges_diff)\n",
    "\n",
    "        # Update the previous frame for the next iteration\n",
    "        prev_frame = frame.copy()\n",
    "\n",
    "    # Release the VideoCapture and VideoWriter objects\n",
    "    video_capture.release()\n",
    "    out_canny.release()\n",
    "    \n",
    "class EdgeDetector:\n",
    "    def __init__(self, min_distance=30, strength=50, temporal_window=10, temporal_weight=0.1):\n",
    "        self.min_distance = min_distance\n",
    "        self.strength = strength\n",
    "        self.temporal_window = temporal_window\n",
    "        self.temporal_weight = temporal_weight\n",
    "        self.prev_frames = []\n",
    "\n",
    "    def remove_noise_edges(self, edges):\n",
    "        cleaned_edges = np.zeros_like(edges)\n",
    "\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > self.min_distance:\n",
    "                cv2.drawContours(cleaned_edges, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "        return cleaned_edges\n",
    "\n",
    "    def enhance_edges(self, edges):\n",
    "        enhanced_edges = cv2.dilate(edges, None, iterations=self.strength)\n",
    "\n",
    "        return enhanced_edges\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        current_edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "        if self.prev_frames:\n",
    "            # Temporal smoothing by blending with nearby frames' edges\n",
    "            combined_edges = current_edges.copy()\n",
    "\n",
    "            for i in range(1, min(len(self.prev_frames), self.temporal_window)+1):\n",
    "                temporal_weight = self.temporal_weight / i  # Decrease weight for farther frames\n",
    "                combined_edges = cv2.addWeighted(combined_edges, 1 - temporal_weight, self.prev_frames[-i], temporal_weight, 0)\n",
    "\n",
    "            # Enhance the combined edges\n",
    "            enhanced_edges = self.enhance_edges(combined_edges)\n",
    "        else:\n",
    "            enhanced_edges = self.enhance_edges(current_edges)\n",
    "\n",
    "        # Update the temporal window\n",
    "        self.prev_frames.insert(0, current_edges)\n",
    "        if len(self.prev_frames) > self.temporal_window:\n",
    "            self.prev_frames.pop()\n",
    "\n",
    "        cleaned_edges = self.remove_noise_edges(enhanced_edges)\n",
    "\n",
    "        return cv2.bitwise_and(frame, frame, mask=cleaned_edges)\n",
    "\n",
    "\n",
    "def process_video_with_canny(input_path, output_path):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "    edge_detector = EdgeDetector()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply Canny and remove static using the EdgeDetector\n",
    "        result = edge_detector.process_frame(frame)\n",
    "\n",
    "        out.write(result)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_video_path = '1.avi'\n",
    "output_canny_video_path = 'temp1.avi'\n",
    "\n",
    "# Apply Canny and remove static\n",
    "apply_canny_and_remove_static(input_video_path, output_canny_video_path)\n",
    "\n",
    "# Process video with enhanced edges using the EdgeDetector\n",
    "input_canny_video_path = output_canny_video_path\n",
    "output_final_video_path = 'output.avi'\n",
    "\n",
    "process_video_with_canny(input_canny_video_path, output_final_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aca1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6310e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4399627f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 55 extracted and saved as motion_detection.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def extract_frame(video_path, frame_number, output_path):\n",
    "    # Open the video file\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Check if the video file opened successfully\n",
    "    if not video_capture.isOpened():\n",
    "        print(\"Error: Unable to open video file\")\n",
    "        return\n",
    "\n",
    "    # Get the total number of frames in the video\n",
    "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Check if the specified frame number is valid\n",
    "    if frame_number < 0 or frame_number >= total_frames:\n",
    "        print(\"Error: Invalid frame number\")\n",
    "        return\n",
    "\n",
    "    # Set the frame position to the specified frame number\n",
    "    video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "    # Read the frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Check if the frame was read successfully\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to read frame\")\n",
    "        return\n",
    "\n",
    "    # Save the frame as an image\n",
    "    cv2.imwrite(output_path, frame)\n",
    "\n",
    "    # Release the video capture object\n",
    "    video_capture.release()\n",
    "\n",
    "    print(f\"Frame {frame_number} extracted and saved as {output_path}\")\n",
    "\n",
    "# Example usage:\n",
    "video_file = \"out1.avi\"\n",
    "output_image = \"motion_detection.jpg\"\n",
    "frame_number = 55  # Change this to the desired frame number\n",
    "\n",
    "extract_frame(video_file, frame_number, output_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2000883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
